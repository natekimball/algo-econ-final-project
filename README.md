# CS 4501 Algorithmic Economics final project: "Learning the Threshold Function: Beyond the VC dimension"

## [Project #5] Learning Threshold Functions: Beyond the VC Dimension

### In class we discussed the celebrated VC dimension on characterizing the expressiveness of a hypothesis class for binary classification tasks. For this project, we will review some concepts in PAC learning and explore a generalization of the VC dimension to the multilclass classification setting.

### The goal of this project is to study the learnability of the class of threshold functions. A threshold function hτ : R → {0, 1}, τ ∈ R, is a function where hτ (x) = 1 if and only if x ≥ τ . Note that each hτ is defined by its threshold value τ . Let H = {hτ : τ ∈ R} be the set of threshold functions.

1. What is the VC dimension of H?

We now learn an unknown threshold function hτ∗ based on the training data labeled by hτ∗ . Specifically, let $$T = {(xi, yi)}^q_{i=1}$$ be a training set1 of q ≥ 1 examples in R × {0, 1}, where (i) xi ∼ D is drawn i.i.d. from an (unknown) distribution D over R; (ii) yi = hτ∗(xi) is the ground truth binary label of xi generated by the unknown threshold function hτ∗.

2. Propose and implement (in any programming languages of your choice) an algorithm that returns a function hτ ∈ H that minimizes the empirical risk w.r.t. T . Next, test your algorithm on training sets of varying sizes and study the performance of the algorithm on unseen data points. As you might have noted, the size of the hypothesis H is infinite. Nevertheless, H is still PAC learnable (as the VC dimension is what matters), and one such a PAC learner was proposed by you in Question 2.

3. Using your answer in Question 1, derive an upper bound on the sample complexity mH(ϵ, δ) of learning H based on the Fundamental Theorem of PAC learning [2]:
$$m_H(ϵ, δ) ≤ \frac{c2 · VCdim(H) · log (1/ϵ) + log (1/δ)}{ϵ} (1)$$
where c2 is some constant, VCdim(H) is the VC dimension of H, ϵ and δ are the PAC parameters.

Everything we have discussed previously are for binary classification tasks. We now extend to the multiclass setting. In particular, define h′τ: R^n → {0, 1}^n, τ ∈ R, n ∈ Z^+, to be a threshold function that operates in higher dimensions; h′τ applies the threshold rule element-wise to the input. Formally, given a vector ⃗x ∈ R^n, and let ⃗y = h′_τ(⃗x); then ⃗y(i) = 1 if and only if ⃗x(i) ≥ τ , i = 1, ..., n. Let H′ = {h′τ: τ ∈ R} be the set of such threshold functions.

4. Given a training set $$T′ = {(⃗xi, ⃗yi)}^q_{i=1}$$ of q ≥ 1 examples in R^n × {0, 1}^n, where data are labeled by an unknown threshold function h∗τ ∈ H′. Propose and implement an algorithm that returns a h′τ ∈ H′ that minimizes the empirical risk w.r.t. T′.

It is easy to see that the problem above is a multiclass classification task. The Natarajan dimension is an extension of the VC dimension to the multiclass setting [1]. To begin with, we first define the notion of shattering in the multiclass context for our learning problem:

### Definition. (Shattering - Multiclass)
A set S of vectors in R^n is shattered by the hypothesis class H′ if the following two conditions are both satisfied:
• Each vector ⃗x ∈ S can be associated with two binary vectors in {0, 1}^n, denoted by ⃗xA and ⃗xB, such that ⃗xA ̸= ⃗xB.
• Consider the 2|S| possible mappings from S to the associated vectors, such that in each mapping Φ, each ⃗x ∈ S is mapped to one of its associated vectors. For
each such mapping Φ, there exists a function hΦ ∈ H′ that produces Φ. That is, hΦ(⃗x) = Φ(⃗x) for all ⃗x ∈ S.

The Natarajan dimension of the hypothesis class H′, denoted by Ndim(H′), is then defined as the maximum size of a shatterable set by H′ [2].

5. What is the Natarajan dimension of H′?

Lastly, we consider a more general version of the threshold function in high dimensions.
In particular, define hˆΓ : R^n → {0, 1}^n, τ ∈ R, n ∈ Z+, to be a threshold function; Γ is an n-tuple where Γ(i) ∈ R is the threshold value for the ith element in the input to hˆΓ, i = 1, ..., n. Formally, given a vector ⃗x ∈ R^n, and let ⃗y = hˆΓ(⃗x); then ⃗y(i) = 1 if and only if ⃗x(i) ≥ Γ(i), i = 1, ..., n. Let Hˆ = {hˆ
Γ : Γ ∈ R^n} be the set of such threshold functions.

6. Show that the Natarajan dimension of Hˆ is at most n.

8. (Bonus question) Show that the Natarajan dimension of Hˆ is n
